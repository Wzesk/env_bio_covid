Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 8
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job stats:
job                         count    min threads    max threads
------------------------  -------  -------------  -------------
add_branch_labels               1              1              1
adjust_metadata_regions         1              1              1
align                           1              8              8
all                             1              1              1
ancestral                       1              1              1
build_align                     1              8              8
calculate_epiweeks              1              1              1
clade_files                     1              1              1
clades                          1              1              1
colors                          1              1              1
combine_samples                 1              1              1
diagnostic                      1              1              1
distances                       1              1              1
emerging_lineages               1              1              1
export                          1              1              1
filter                          1              1              1
finalize                        1              1              1
include_hcov19_prefix           1              1              1
index_sequences                 1              1              1
logistic_growth                 1              1              1
mask                            1              1              1
mutational_fitness              1              1              1
recency                         1              1              1
refine                          1              1              1
rename_emerging_lineages        1              1              1
sanitize_metadata               1              1              1
subsample                       1              1              1
tip_frequencies                 1              1              1
traits                          1              1              1
translate                       1              1              1
tree                            1              8              8
total                          31              1              8

Select jobs to execute...

[Fri Nov 26 22:59:00 2021]
Job 11: 
        Aligning sequences to defaults/reference_seq.fasta
            - gaps relative to reference are considered real
        


        python3 scripts/sanitize_sequences.py             --sequences data/hcov_north-america.fasta             --strip-prefixes hCoV-19/ SARS-CoV-2/             --output /dev/stdout 2> logs/sanitize_sequences_b_1_526.txt             | nextalign             --jobs=8             --reference defaults/reference_seq.fasta             --genemap defaults/annotation.gff             --genes ORF1a,ORF1b,S,ORF3a,E,M,ORF6,ORF7a,ORF7b,ORF8,N,ORF9b             --sequences /dev/stdin             --output-dir results/translations             --output-basename seqs_b_1_526             --output-fasta results/aligned_b_1_526.fasta             --output-insertions results/insertions_b_1_526.tsv > logs/align_b_1_526.txt 2>&1;
        xz -2 results/aligned_b_1_526.fasta;
        xz -2 results/translations/seqs_b_1_526*.fasta
        
[Fri Nov 26 22:59:43 2021]
Finished job 11.
1 of 31 steps (3%) done
Select jobs to execute...

[Fri Nov 26 22:59:44 2021]
rule sanitize_metadata:
    input: data/hcov_north-america.tsv
    output: results/sanitized_metadata_b_1_526.tsv.xz
    log: logs/sanitize_metadata_b_1_526.txt
    jobid: 12
    benchmark: benchmarks/sanitize_metadata_b_1_526.txt
    wildcards: origin=b_1_526
    resources: tmpdir=/tmp, mem_mb=2000


        python3 scripts/sanitize_metadata.py             --metadata data/hcov_north-america.tsv             --metadata-id-columns strain name 'Virus name'             --database-id-columns 'Accession ID' gisaid_epi_isl genbank_accession             --parse-location-field Location             --rename-fields 'Virus name=strain' Type=type 'Accession ID=gisaid_epi_isl' 'Collection date=date' 'Additional location information=additional_location_information' 'Sequence length=length' Host=host 'Patient age=patient_age' Gender=sex Clade=GISAID_clade 'Pango lineage=pango_lineage' pangolin_lineage=pango_lineage Lineage=pango_lineage 'Pangolin version=pangolin_version' Variant=variant 'AA Substitutions=aa_substitutions' aaSubstitutions=aa_substitutions 'Submission date=date_submitted' 'Is reference?=is_reference' 'Is complete?=is_complete' 'Is high coverage?=is_high_coverage' 'Is low coverage?=is_low_coverage' N-Content=n_content GC-Content=gc_content             --strip-prefixes hCoV-19/ SARS-CoV-2/                          --output results/sanitized_metadata_b_1_526.tsv.xz 2>&1 | tee logs/sanitize_metadata_b_1_526.txt
        

[Fri Nov 26 22:59:44 2021]
rule clade_files:
    input: defaults/clades.tsv
    output: results/b_lineage/clades.tsv
    jobid: 22
    benchmark: benchmarks/clade_files_b_lineage.txt
    wildcards: build_name=b_lineage
    resources: tmpdir=/tmp


        cat defaults/clades.tsv > results/b_lineage/clades.tsv
        
[Fri Nov 26 22:59:44 2021]
Finished job 22.
2 of 31 steps (6%) done
[Fri Nov 26 23:00:05 2021]
Finished job 12.
3 of 31 steps (10%) done
Select jobs to execute...

[Fri Nov 26 23:00:05 2021]
Job 13: Scanning metadata results/sanitized_metadata_b_1_526.tsv.xz for problematic sequences. Removing sequences with >20 deviation from the clock and with more than 1.


        python3 scripts/diagnostic.py             --metadata results/sanitized_metadata_b_1_526.tsv.xz             --clock-filter 20             --rare-mutations 100             --clock-plus-rare 100             --snp-clusters 1             --output-exclusion-list results/to-exclude_b_1_526.txt 2>&1 | tee logs/diagnostics_b_1_526.txt
        
[Fri Nov 26 23:00:17 2021]
Finished job 13.
4 of 31 steps (13%) done
Select jobs to execute...

[Fri Nov 26 23:00:17 2021]
Job 10: 
        Filtering alignment results/aligned_b_1_526.fasta.xz -> results/filtered_b_1_526.fasta.xz
          - excluding strains in defaults/exclude.txt results/to-exclude_b_1_526.txt
          - including strains in b1526_profiles/include.txt
          - min length: 27000
        


        augur filter             --sequences results/aligned_b_1_526.fasta.xz             --metadata results/sanitized_metadata_b_1_526.tsv.xz             --include b1526_profiles/include.txt             --max-date 2021-11-27             --min-date 2019.74             --exclude-ambiguous-dates-by any             --exclude defaults/exclude.txt results/to-exclude_b_1_526.txt             --exclude-where division='USA'            --min-length 27000             --output results/filtered_b_1_526.fasta 2>&1 | tee logs/filtered_b_1_526.txt;
        xz -2 results/filtered_b_1_526.fasta
        
[Fri Nov 26 23:00:39 2021]
Finished job 10.
5 of 31 steps (16%) done
Select jobs to execute...

[Fri Nov 26 23:00:39 2021]
Job 14: 
        Index sequence composition for faster filtering.
        


        augur index             --sequences results/filtered_b_1_526.fasta.xz             --output results/combined_sequence_index.tsv.xz 2>&1 | tee logs/index_sequences.txt
        
[Fri Nov 26 23:01:02 2021]
Finished job 14.
6 of 31 steps (19%) done
Select jobs to execute...

[Fri Nov 26 23:01:02 2021]
Job 15: 
        Subsample all sequences by 'lineage-focus' scheme for build 'b_lineage' with the following parameters:

         - group by: --group-by year month
         - sequences per group: 
         - subsample max sequences: 1000
         - min-date: 
         - max-date: 
         - 
         - exclude: 
         - include: 
         - query: --query "(pango_lineage == 'B.1.526' | pango_lineage == 'B.1.526.1' | pango_lineage == 'B.1.526.2')"
         - priority: 
        


        augur filter             --sequences results/filtered_b_1_526.fasta.xz             --metadata results/sanitized_metadata_b_1_526.tsv.xz             --sequence-index results/combined_sequence_index.tsv.xz             --include b1526_profiles/include.txt             --exclude defaults/exclude.txt                                                                 --query "(pango_lineage == 'B.1.526' | pango_lineage == 'B.1.526.1' | pango_lineage == 'B.1.526.2')"                                       --group-by year month                          1000                          --output results/b_lineage/sample-lineage-focus.fasta             --output-strains results/b_lineage/sample-lineage-focus.txt 2>&1 | tee logs/subsample_b_lineage_lineage-focus.txt
        
[Fri Nov 26 23:01:21 2021]
Error in rule subsample:
    jobid: 15
    output: results/b_lineage/sample-lineage-focus.fasta, results/b_lineage/sample-lineage-focus.txt
    log: logs/subsample_b_lineage_lineage-focus.txt (check log file(s) for error message)
    shell:
        
        augur filter             --sequences results/filtered_b_1_526.fasta.xz             --metadata results/sanitized_metadata_b_1_526.tsv.xz             --sequence-index results/combined_sequence_index.tsv.xz             --include b1526_profiles/include.txt             --exclude defaults/exclude.txt                                                                 --query "(pango_lineage == 'B.1.526' | pango_lineage == 'B.1.526.1' | pango_lineage == 'B.1.526.2')"                                       --group-by year month                          1000                          --output results/b_lineage/sample-lineage-focus.fasta             --output-strains results/b_lineage/sample-lineage-focus.txt 2>&1 | tee logs/subsample_b_lineage_lineage-focus.txt
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /vortexfs1/omics/env-bio/collaboration/env_bio_covid/ncov/.snakemake/log/2021-11-26T225853.800913.snakemake.log
